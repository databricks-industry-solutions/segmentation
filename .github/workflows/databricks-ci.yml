name: Databricks CI/CD Pipeline

on:
  pull_request:
    branches:
      - main
      - feature/dabsdeploy
  push:
    branches:
      - main
      - feature/dabsdeploy

env:
  DATABRICKS_TOKEN: ${{ secrets.DB_TOKEN }}

jobs:
  databricks-deploy:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Databricks CLI
        run: |
          pip install databricks-cli

      - name: Configure Databricks CLI
        run: |
          echo "$DATABRICKS_TOKEN" | databricks configure --token

      - name: Create or get serverless SQL warehouse
        id: warehouse
        run: |
          # Check if warehouse exists, create if not
          WAREHOUSE_ID=$(databricks warehouses list --output json | jq -r '.warehouses[] | select(.name=="CI-Serverless") | .id' || echo "")
          if [ -z "$WAREHOUSE_ID" ]; then
            echo "Creating serverless warehouse..."
            WAREHOUSE_ID=$(databricks warehouses create \
              --name "CI-Serverless" \
              --cluster-size "2X-Small" \
              --min-num-clusters 1 \
              --max-num-clusters 1 \
              --auto-stop-mins 10 \
              --warehouse-type "PRO" \
              --enable-serverless-compute \
              --output json | jq -r '.id')
          fi
          echo "warehouse_id=$WAREHOUSE_ID" >> $GITHUB_OUTPUT

      - name: Validate bundle
        run: |
          databricks bundle validate --target dev

      - name: Deploy bundle
        run: |
          databricks bundle deploy --target dev

      - name: Run customer segmentation pipeline
        run: |
          # Start the DLT pipeline
          PIPELINE_ID=$(databricks bundle resources --target dev --output json | jq -r '.resources.pipelines.customer_segmentation_pipeline.id')
          databricks pipelines start-update --pipeline-id $PIPELINE_ID --full-refresh

          # Wait for completion and check status
          while true; do
            STATUS=$(databricks pipelines get-update --pipeline-id $PIPELINE_ID --update-id $(databricks pipelines list-updates --pipeline-id $PIPELINE_ID --max-results 1 --output json | jq -r '.updates[0].update_id') --output json | jq -r '.update.state')
            echo "Pipeline status: $STATUS"
            
            if [[ "$STATUS" == "COMPLETED" ]]; then
              echo "Pipeline completed successfully"
              break
            elif [[ "$STATUS" == "FAILED" || "$STATUS" == "CANCELED" ]]; then
              echo "Pipeline failed with status: $STATUS"
              exit 1
            fi
            
            sleep 30
          done

      - name: Cleanup deployment
        if: always()
        run: |
          databricks bundle destroy --target dev --auto-approve